{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T13:49:27.175105Z",
     "start_time": "2020-03-26T13:49:26.523872Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import mae\n",
    "from tensorflow.keras.utils import normalize\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T13:55:38.436353Z",
     "start_time": "2020-03-26T13:55:31.625263Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('../Data/X.csv')\n",
    "Y = pd.read_csv('../Data/Y.csv')\n",
    "\n",
    "# load feature type columns\n",
    "with open('../Data/feature_types.json', 'r') as f:\n",
    "    categorical_features, numeric_features = json.load(f)\n",
    "\n",
    "# one-hot encoding cat features\n",
    "X_onehot = one_hot_encoding(X, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T13:55:41.021359Z",
     "start_time": "2020-03-26T13:55:40.122205Z"
    }
   },
   "outputs": [],
   "source": [
    "# parse args\n",
    "use_simple_features = False\n",
    "use_best_features = False\n",
    "split_mode = 'fix_transfer'\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = dataset_split(X, Y,\n",
    "                                                 split_mode=split_mode,\n",
    "                                                 use_simple_features=use_simple_features,\n",
    "                                                 use_best_features=use_best_features,\n",
    "                                                 num_features=0)\n",
    "X_train_oh, X_test_oh, _, _ = dataset_split(X_onehot, Y,\n",
    "                                            split_mode=split_mode,\n",
    "                                            use_simple_features=use_simple_features,\n",
    "                                            use_best_features=use_best_features,\n",
    "                                            num_features=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T02:28:00.814717Z",
     "start_time": "2020-03-27T02:28:00.810727Z"
    }
   },
   "outputs": [],
   "source": [
    "shift_mode = 'svd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T02:28:25.180252Z",
     "start_time": "2020-03-27T02:28:01.395741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stats] Var. explanation ratio: 1.0000\n"
     ]
    }
   ],
   "source": [
    "if shift_mode is 'svd':\n",
    "    X_ = pd.concat((X_train, X_test), axis=0)\n",
    "    train_idx = range(0,X_train.shape[0])\n",
    "    test_idx = range(X_train.shape[0],X_.shape[0])\n",
    "    \n",
    "    # define transformer\n",
    "    svd = TruncatedSVD(n_components=150, n_iter=20, random_state=1326)\n",
    "    svd.fit(X_.T)\n",
    "    print(\"[Stats] Var. explanation ratio: {:.4f}\".format(svd.explained_variance_ratio_.sum()))\n",
    "    \n",
    "    # transform dataset\n",
    "    X_new = svd.components_.T\n",
    "\n",
    "elif shift_mode is 'ae':\n",
    "    X_ = pd.concat((X_train_oh, X_test_oh), axis=0)\n",
    "    \n",
    "    train_idx = range(0,X_train.shape[0])\n",
    "    test_idx = range(X_train.shape[0],X_.shape[0])\n",
    "    \n",
    "    # define transformer\n",
    "    x_in = Input(shape=(X_train_oh.shape[1],))\n",
    "    h = Dense(units=512,use_bias=True,kernel_initializer=he_normal(),activation=None)(x_in)\n",
    "    h = LeakyReLU(0.1)(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Dense(units=X_train_oh.shape[1],use_bias=True,\n",
    "              kernel_initializer=he_normal(),activation='relu')(h)\n",
    "    \n",
    "    ae = Model(inputs=x_in, outputs=h)\n",
    "    ae.compile(loss='mse',optimizer=Adam(5e-4))\n",
    "    hist = ae.fit(normalize(X_.values), normalize(X_.values),\n",
    "                       batch_size=512, epochs=50,\n",
    "                       shuffle=True,verbose=1)\n",
    "    \n",
    "    # transform dataset\n",
    "    Transformer = Model(inputs=ae.input, outputs=ae.layers[-2].output)\n",
    "    X_new = Transformer.predict(normalize(X_.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T02:29:21.838397Z",
     "start_time": "2020-03-27T02:29:21.834447Z"
    }
   },
   "outputs": [],
   "source": [
    "regressor = 'mlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T02:39:08.136246Z",
     "start_time": "2020-03-27T02:29:22.629950Z"
    }
   },
   "outputs": [],
   "source": [
    "if regressor is 'gbm':\n",
    "    sp = time.time()\n",
    "    train_data = lgb.Dataset(X_new[train_idx], y_train)\n",
    "    test_data = lgb.Dataset(X_new[test_idx], y_test, reference=train_data)\n",
    "\n",
    "    params = {\n",
    "        'objective':'regression',\n",
    "        'boosting':'gbdt',\n",
    "        'metric':'mae',\n",
    "        'num_rounds':20000,\n",
    "        'learning_rate':0.002,\n",
    "        'max_depth':10,\n",
    "        'num_leaves':200,\n",
    "        'feature_fraction':0.5,\n",
    "        'bagging_fraction':0.9,\n",
    "        'bagging_freq':200,\n",
    "        'verbose':0\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params, train_data,\n",
    "                    valid_sets=[test_data, train_data],\n",
    "                    valid_names=['test','train'],\n",
    "                    verbose_eval=200,\n",
    "                    early_stopping_rounds=100)\n",
    "    print(\"[Duration] {:.2f} sec.\".format(time.time() - sp))\n",
    "\n",
    "\n",
    "    # evaluate\n",
    "    y_pred = gbm.predict(X_new[test_idx],num_iteration=gbm.best_iteration)\n",
    "    print(\"[LightGBM] mae: {:.2f} | mape: {:.2f}% | mspe: {:.2f}%\".format(\n",
    "        mae(y_pred, y_test),\n",
    "        100 * mape(y_pred,y_test), 100 * mspe(y_pred, y_test)))\n",
    "\n",
    "elif regressor is 'mlp':\n",
    "    sp = time.time()\n",
    "    \n",
    "    x_in = Input(shape=(X_new.shape[1],))\n",
    "    h = Dense(units=512,use_bias=True,kernel_initializer=he_normal(),activation=None)(x_in)\n",
    "    h = LeakyReLU(0.1)(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    h = Dense(units=256,use_bias=True,kernel_initializer=he_normal(),activation=None)(h)\n",
    "    h = LeakyReLU(0.1)(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    h = Dense(units=128,use_bias=True,kernel_initializer=he_normal(),activation=None)(h)\n",
    "    h = LeakyReLU(0.1)(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    h = Dense(units=64,use_bias=True,kernel_initializer=he_normal(),activation=None)(h)\n",
    "    h = LeakyReLU(0.1)(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    h = Dense(units=1,use_bias=True,kernel_initializer=he_normal(),activation='relu')(h)\n",
    "    \n",
    "    mlp = Model(inputs=x_in, outputs=h)\n",
    "    mlp.compile(loss='mse',optimizer=Adam(3e-4),metrics=['mae'])\n",
    "    print(\"[Num. Params.] {:d}\".format(mlp.count_params()))\n",
    "    hist = mlp.fit(X_new[train_idx], y_train, batch_size=512, epochs=200,\n",
    "                   shuffle=True, verbose=2,\n",
    "                   validation_data=[X_new[test_idx],y_test])\n",
    "    \n",
    "    print(\"[Duration] {:.2f} sec.\".format(time.time() - sp))\n",
    "    \n",
    "    # evaluate\n",
    "    y_pred = mlp.predict(X_new[test_idx]).reshape(-1)\n",
    "    print(\"[MLP] mae: {:.2f} | mape: {:.2f}% | mspe: {:.2f}%\".format(\n",
    "        mae(y_pred, y_test),\n",
    "        100 * mape(y_pred,y_test),\n",
    "        100 * mspe(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T02:59:08.456406Z",
     "start_time": "2020-03-27T02:59:08.435465Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def gaussian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    '''\n",
    "    将源域数据和目标域数据转化为核矩阵，即上文中的K\n",
    "    Params: \n",
    "        source: 源域数据（n * len(x))\n",
    "        target: 目标域数据（m * len(y))\n",
    "        kernel_mul: \n",
    "        kernel_num: 取不同高斯核的数量\n",
    "        fix_sigma: 不同高斯核的sigma值\n",
    "    Return:\n",
    "        sum(kernel_val): 多个核矩阵之和\n",
    "    '''\n",
    "    n_samples = int(source.size()[0])+int(target.size()[0])# 求矩阵的行数，一般source和target的尺度是一样的，这样便于计算\n",
    "    total = torch.cat([source, target], dim=0)#将source,target按列方向合并\n",
    "    #将total复制（n+m）份\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    #将total的每一行都复制成（n+m）行，即每个数据都扩展成（n+m）份\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    #求任意两个数据之间的和，得到的矩阵中坐标（i,j）代表total中第i行数据和第j行数据之间的l2 distance(i==j时为0）\n",
    "    L2_distance = ((total0-total1)**2).sum(2) \n",
    "    #调整高斯核函数的sigma值\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "    #以fix_sigma为中值，以kernel_mul为倍数取kernel_num个bandwidth值（比如fix_sigma为1时，得到[0.25,0.5,1,2,4]\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "    #高斯核函数的数学表达式\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "    #得到最终的核矩阵\n",
    "    return sum(kernel_val)#/len(kernel_val)\n",
    "\n",
    "\n",
    "def mmd_rbf(source, target, kernel_mul=2.0, batch_size=32,kernel_num=5, fix_sigma=None):\n",
    "    '''\n",
    "    计算源域数据和目标域数据的MMD距离\n",
    "    Params: \n",
    "        source: 源域数据（n * len(x))\n",
    "        target: 目标域数据（m * len(y))\n",
    "        kernel_mul: \n",
    "        kernel_num: 取不同高斯核的数量\n",
    "        fix_sigma: 不同高斯核的sigma值\n",
    "    Return:\n",
    "        loss: MMD loss\n",
    "    '''\n",
    "    batch_size = int(source.size()[0])#一般默认为源域和目标域的batchsize相同\n",
    "    kernels = guassian_kernel(source, target,\n",
    "        kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "    #根据式（3）将核矩阵分成4部分\n",
    "    XX = kernels[:batch_size, :batch_size]\n",
    "    YY = kernels[batch_size:, batch_size:]\n",
    "    XY = kernels[:batch_size, batch_size:]\n",
    "    YX = kernels[batch_size:, :batch_size]\n",
    "    loss = torch.mean(XX + YY - XY - YX)\n",
    "    return loss#因为一般都是n==m，所以L矩阵一般不加入计算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T02:59:14.887224Z",
     "start_time": "2020-03-27T02:59:14.842379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0162)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd_rbf(torch.Tensor(X_new[128:256]), torch.Tensor(X_new[-128:]))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
