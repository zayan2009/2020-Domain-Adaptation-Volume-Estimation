{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Reshape, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Embedding, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import he_normal, constant\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsRegressor\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T04:01:53.422299Z",
     "start_time": "2020-03-22T04:01:53.416314Z"
    }
   },
   "outputs": [],
   "source": [
    "avi_train_seg = np.load('../Data/avi_train_seg.npy')\n",
    "trj_train_seg = np.load('../Data/trj_train_seg.npy')\n",
    "lane_functions = np.load('../Data/lane_functions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T04:01:53.439250Z",
     "start_time": "2020-03-22T04:01:53.431279Z"
    }
   },
   "outputs": [],
   "source": [
    "num_lanes = lane_functions.sum(axis=1)\n",
    "lane_functions = pd.DataFrame(lane_functions,columns=['through','left','right',\n",
    "                                                      'thr_left','thr_right','u_turn'])\n",
    "lane_functions['linkIdx'] = np.arange(1,25)\n",
    "lane_functions['num_lanes'] = num_lanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Sample Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T04:01:59.545289Z",
     "start_time": "2020-03-22T04:01:59.536314Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_sample(trj_train_seg):\n",
    "    data = pd.DataFrame(columns=['linkIdx','datetime','volume'])\n",
    "    for approach in range(24):\n",
    "        table = pd.DataFrame(np.zeros((30 * 144,3)),columns=['linkIdx','datetime','volume'])\n",
    "        table.iloc[:,0] = approach + 1\n",
    "        for day in range(30):\n",
    "            if day < 9:\n",
    "                datetime = [pd.to_datetime('2018010' + str(day + 1)) + pd.Timedelta(i * 10,unit='m') for i in range(144)]\n",
    "            else:\n",
    "                datetime = [pd.to_datetime('201801' + str(day + 1)) + pd.Timedelta(i * 10,unit='m') for i in range(144)]\n",
    "            table.iloc[144 * day:144 * (day + 1),2] = trj_train_seg[day,:,approach]\n",
    "            table.iloc[144 * day:144 * (day + 1),1] = datetime\n",
    "        data = pd.concat((data,table))\n",
    "    data['linkIdx'] = data['linkIdx'].astype('int')\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "    data['volume'] = data['volume'].astype('float')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T04:02:26.161111Z",
     "start_time": "2020-03-22T04:02:00.336173Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Basic Stats] num. of samples: 103680\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_sample(trj_train_seg), get_sample(avi_train_seg)\n",
    "print(\"[Basic Stats] num. of samples: {:d}\".format(X.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T04:02:34.562601Z",
     "start_time": "2020-03-22T04:02:33.476509Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Basic Stats] dim. of features: 15\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Feature Engineering\n",
    "# =============================\n",
    "\n",
    "X = pd.merge(X,lane_functions)\n",
    "X['hour'] = X['datetime'].map(lambda x:x.hour)\n",
    "X['weekday'] = X['datetime'].map(lambda x:x.weekday())\n",
    "\n",
    "def holiday(x):\n",
    "    if x.month == 1 and x.day == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def peak(x):\n",
    "    if 7 < x.hour < 9:\n",
    "        return 1\n",
    "    elif 11 < x.hour < 13:\n",
    "        return 2\n",
    "    elif 17 < x.hour < 19:\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def itv_cnt(x, itv_length=600):\n",
    "    return (x.hour * 3600 + x.minute * 60) // itv_length\n",
    "\n",
    "X['interval'] = X['datetime'].map(lambda x:itv_cnt(x))\n",
    "X['holiday'] = X['datetime'].map(lambda x:holiday(x))\n",
    "X['peak'] = X['datetime'].map(lambda x:peak(x))\n",
    "X['linkIdx'] = X['linkIdx'].astype(int)\n",
    "\n",
    "print(\"[Basic Stats] dim. of features: {:d}\".format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T04:02:36.672703Z",
     "start_time": "2020-03-22T04:02:36.666718Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def merge_volume_features(X, feature_cols, aggfuncs=['mean', 'median', 'std']):\n",
    "    \n",
    "    for feature in feature_cols:\n",
    "        for fn in aggfuncs:\n",
    "            df = X.pivot_table(index='linkIdx',\n",
    "                               columns=feature,\n",
    "                               values='volume',\n",
    "                               aggfunc=fn).reset_index()\n",
    "            df.columns = ['linkIdx'] + list(df.columns[1:])\n",
    "            df = df.melt(id_vars=['linkIdx'],\n",
    "                         value_vars=list(df.columns[1:]),\n",
    "                         var_name=feature,\n",
    "                         value_name=feature + '_' + fn + '_volume')\n",
    "            df[feature] = pd.to_numeric(df[feature])\n",
    "            X = pd.merge(X, df, on=['linkIdx',feature])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T04:02:40.571383Z",
     "start_time": "2020-03-22T04:02:37.277228Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_cols = ['through', 'left', 'right', 'thr_left',\n",
    "                'thr_right', 'u_turn', 'num_lanes', 'hour',\n",
    "                'weekday', 'interval', 'holiday', 'peak']\n",
    "X = merge_volume_features(X, feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_pred, y_test):\n",
    "    return np.sum(np.abs(y_pred - y_test) * y_test) / np.sum(y_test)\n",
    "\n",
    "def mape(y_pred, y_test):\n",
    "    return np.sum(np.abs(y_pred - y_test)) / np.sum(y_test)\n",
    "\n",
    "def mspe(y_pred, y_test):\n",
    "    return np.sum(np.square(y_pred - y_test)) / np.sum(np.square(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
